{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "485ef2b3",
   "metadata": {},
   "source": [
    "## Boyuan Yao 19307110202\n",
    "This jupyter notebook is for TA to run my code. I use python 3.8.12 to finish all my codes. Please run the following setup codes first (make sure this notebook is running within the directory as you download from  my github page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97680202",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "('X_train: ', (55000, 784))\n",
      "('y_train: ', (55000,))\n",
      "('X_val: ', (5000, 784))\n",
      "('y_val: ', (5000,))\n",
      "('X_test: ', (10000, 784))\n",
      "('y_test: ', (10000,))\n"
     ]
    }
   ],
   "source": [
    "# Some common setups\n",
    "import numpy as np\n",
    "from urllib import request\n",
    "import gzip\n",
    "import pickle\n",
    "from data_utils import * # Data processing\n",
    "from solver import * # Solver for updating the model\n",
    "from twolayernet import * # The two layer net model\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (20.0, 16.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Load the MNIST data\n",
    "\n",
    "data = load_mnist()\n",
    "for k, v in list(data.items()):\n",
    "    print(('%s: ' % k, v.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52565dab",
   "metadata": {},
   "source": [
    "## Part 1: Hyperparameter searching\n",
    "This part is for training, you could change the learning rate, number of hidden_units, regulariation strength candidates in the following cell. It will print the test result of the best model on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb41c882",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 784\n",
    "num_classes = 10\n",
    "\n",
    "# Choice of hyperparameters\n",
    "lr_rate = [1e-3, 1e-4] # Learning rate\n",
    "hidden_units = [100, 200, 300] # Number of hidden units\n",
    "regs = [1e-1, 1e-2, 1e-3] # Regularization strength\n",
    "best_acc = 0.0\n",
    "best_model = None\n",
    "best_params = []\n",
    "\n",
    "# Searching process\n",
    "for lr in lr_rate:\n",
    "    for units in hidden_units:\n",
    "        for reg in regs:\n",
    "            model = TwoLayerNet(input_size, \n",
    "                                units, \n",
    "                                num_classes, \n",
    "                                reg=reg)\n",
    "            solver = Solver(model, \n",
    "                            data, \n",
    "                            optim_config={\n",
    "                                'learning_rate': lr\n",
    "                            },\n",
    "                            verbose = False, # This is for \n",
    "                                             # printing the testing information\n",
    "                            save_model = False, # This is for \n",
    "                                                # saving the current model\n",
    "                            num_epochs = 20) # This is for number of epochs\n",
    "            solver.train()\n",
    "            # Print each parameter's final result on the val set\n",
    "            print(\"=================================================\")\n",
    "            print(\"learning rate = %f, hidden units = %d\\nregularization strength = %f, accuracy on val = %f\"\n",
    "                  % (lr, units, reg, solver.best_val_acc))\n",
    "            print(\"=================================================\")\n",
    "            if solver.best_val_acc > best_acc:\n",
    "                best_model = solver.model\n",
    "                best_acc = solver.best_val_acc\n",
    "                best_params = [lr, units, reg]\n",
    "                \n",
    "# Testing the best model\n",
    "best_model.reg = 0.0\n",
    "y_test_pred = np.argmax(best_model.loss(data['X_test']), axis=1)\n",
    "print('Test set accuracy: ', (y_test_pred == data['y_test']).mean())\n",
    "print(\"Best parameters:\")\n",
    "print(\"Learning rate:\", best_params[0])\n",
    "print(\"Hidden units:\", best_params[1])\n",
    "print(\"Regularization strength:\", best_params[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b2c00e",
   "metadata": {},
   "source": [
    "If you want to save the best model, run the following code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01968c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the best model, you could change the file name as you want\n",
    "np.save(\"best_model.npy\", best_model.params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "821be774",
   "metadata": {},
   "source": [
    "## Part 2: Loading model and testing\n",
    "In this part you could load the model (only for MNIST dataset and the two layer model I construct as in the report) and testing the model you load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0686e9cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy:  0.976\n"
     ]
    }
   ],
   "source": [
    "# Loading the parameters\n",
    "# The parameters should be stored in a dictionary with the following form\n",
    "# params['W1'] and params['b1'] are the weight and bias for the first layer\n",
    "# params['W2'] and params['b2'] are the weight and bias for scores computing\n",
    "\n",
    "# You could change the file name as you want\n",
    "params = np.load(\"best_model.npy\", allow_pickle=True).item()\n",
    "model = TwoLayerNet(784, params['W1'].shape[1], 10, params=params)\n",
    "\n",
    "# Testing\n",
    "y_test_pred = np.argmax(model.loss(data['X_test']), axis=1)\n",
    "print('Test set accuracy: ', (y_test_pred == data['y_test']).mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('py38')",
   "language": "python",
   "name": "python3812jvsc74a57bd0e340a0a01ab186b377b016c01aa7d5d1230eddf285ffed81230a024c78a4da64"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
